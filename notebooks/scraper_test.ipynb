{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import system tools\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Import scrapy\n",
    "import scrapy\n",
    "\n",
    "# Import the CrawlerProcess\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "# # Import the Sentiment Analyzer\n",
    "notebook_dir = Path().resolve()\n",
    "project_dir = notebook_dir.parent\n",
    "module_dir = project_dir / \"stock_sentiment\"\n",
    "\n",
    "if str(project_dir) not in sys.path:\n",
    "    sys.path.append(str(project_dir))\n",
    "\n",
    "import spacy\n",
    "from stock_sentiment.sentiment_analysis import StockSentimentAnalyzer  # noqa: E402"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analyzer\n",
    "\n",
    "This section is for loading and initializing the sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Constants\n",
    "MODEL = \"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\"\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "# Initialize NLP tools\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "analyzer = StockSentimentAnalyzer(MODEL, MAX_LENGTH, nlp)\n",
    "stock_symbol = \"NVDA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary before starting the spider\n",
    "yf_dict = {\n",
    "    \"title\": [],\n",
    "    \"url\": [],\n",
    "    \"outlet\": [],\n",
    "    \"author\": [],\n",
    "    \"datetime\": [],\n",
    "}\n",
    "\n",
    "\n",
    "# Create the Spider class\n",
    "class FinancialSpider(scrapy.Spider):\n",
    "    name = \"yf-spider\"\n",
    "\n",
    "    # start_requests method\n",
    "    def start_requests(self):\n",
    "        # URL for the first page to scrape from\n",
    "        urls = [\"https://finance.yahoo.com/\", \"https://finance.yahoo.com/news/\"]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse_main_page)\n",
    "\n",
    "    def parse_main_page(self, response):\n",
    "        links = response.css(\n",
    "            \"section.mainContainer .container div.content a.titles::attr(href)\"\n",
    "        ).extract()\n",
    "\n",
    "        for link in links:\n",
    "            yield response.follow(url=link, callback=self.parse_sub_page)\n",
    "\n",
    "    def parse_sub_page(self, response):\n",
    "        title = response.css(\"div.caas-title-wrapper h1::text\").extract_first()\n",
    "        url = response.url\n",
    "        outlet = response.css(\n",
    "            \"div.caas-logo span.caas-attr-provider::text\"\n",
    "        ).extract_first()\n",
    "        author = response.css(\"div.caas-attr-item-author ::text\").extract_first()\n",
    "        dt = response.css(\n",
    "            \"div.caas-attr-time-style time::attr(datetime)\"\n",
    "        ).extract_first()\n",
    "\n",
    "        yf_dict[\"title\"].append(title)\n",
    "        yf_dict[\"url\"].append(url)\n",
    "        yf_dict[\"outlet\"].append(outlet)\n",
    "        yf_dict[\"author\"].append(author)\n",
    "        yf_dict[\"datetime\"].append(dt)\n",
    "\n",
    "        links = response.css(\"a.yahoo-link::attr(href)\").extract()\n",
    "        for link in links:\n",
    "            yield response.follow(url=link, callback=self.parse_sub_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Spider\n",
    "process = CrawlerProcess()\n",
    "process.crawl(FinancialSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in yf_dict.keys():\n",
    "    print(key, len(yf_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(yf_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df[\"url\"].str.contains(\"finance.yahoo.com\")]\n",
    "print(filtered_df.shape)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = {stock_symbol: []}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    url = row[\"url\"]\n",
    "    sentiment_score = analyzer.analyze_stock_sentiment(url, stock_symbol)\n",
    "    sentiment_scores[stock_symbol].append(sentiment_score)\n",
    "\n",
    "sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
